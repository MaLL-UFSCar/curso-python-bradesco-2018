{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão logística\n",
    "\n",
    "Apesar do nome, regressão logística é geralmente utilizada como um algoritmo de classificação. De certa forma, pode ser visto como um cálculo da probabilidade de um evento ocorrer ou não, sendo assim geralmente associado a saídas binárias (como prever se um determinado produto vai ser vendido ou não para um cliente, ou se um paciente conseguirá se curar com um determinado tratamento ou não). No entanto, é possível generalizar o modelo para tarefas de classificação não-binária.\n",
    "\n",
    "Similar à regressão linear, a regressão logística também dá como resultado um coeficiente e uma constante chamada de _intercept_. Esses números não são utilizados para formar uma combinação linear (como uma reta), mas sim na função logística (também chamada de curva sigmóide:\n",
    "\n",
    "$f(x) = \\dfrac{1}{1 + \\exp(-(k\\cdot (x - x_0)))}$\n",
    "\n",
    "Onde $\\exp(v) = e^v$, a famosa função exponencial com base natural e.\n",
    "\n",
    "Essa não é a forma geral da função logística, mas é a forma que utilizaremos na regressão logística. Vamos visualizar essa curva com alguns valores diferentes de $k$ e $x_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoide(x, k, x0):\n",
    "    return 1 / (1 + np.exp(-k * (x - x0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-10, 10, 200)\n",
    "plt.plot(x, sigmoide(x, k=1, x0=0), color='blue')\n",
    "plt.plot(x, sigmoide(x, k=1, x0=5), color='red')\n",
    "plt.plot(x, sigmoide(x, k=0.5, x0=0), color='green')\n",
    "plt.plot(x, sigmoide(x, k=2, x0=0), color='black')\n",
    "plt.axhline(0.5, color='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também é possível inverter a curva, calculando a probabilidade do evento não ocorrer. É possível visualizar esse evento tanto calculando a probabilidade complementar $1 - x$ ou negando o valor $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, 1 - sigmoide(x, k=1, x0=0), color='red')\n",
    "plt.plot(x, sigmoide(x, k=-1, x0=1), color='blue');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propriedades importantes da função logística:\n",
    "\n",
    "- a variável de entrada $x$ toma valores em toda a reta, $-\\infty < x < \\infty$\n",
    "- o resultado da função é no intervalo $0 < f(x) < 1$, com os extremos sendo os limites, $\\lim_{x\\to-\\infty} f(x) = 0$ e $\\lim_{x\\to\\infty} f(x) = 1$\n",
    "- o ponto onde $x = x_0$ é o resultado 0.5, $f(x_0) = 0.5$\n",
    "- o valor de $k$ determina quão \"íngreme\" é a curva, com valores maiores de $k$ gerando uma curva mais \"vertical\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na regressão logística, o algoritmo é responsável por encontrar os valores de $k$ e $x_0$ baseado nos dados que fornecemos. Assim, criamos uma função logística que calcula a probabilidade estimada do nosso evento ocorrer, e podemos usar essa função em novos exemplos para determinar se a maior chance é do evento ocorrer ou não.\n",
    "\n",
    "No entanto, o scikit-learn possui versões mais complexas do método, que utilizam parâmetros de regularização. Assim, não utilizaremos nossa função logística para tentar recriar a curva aproximada, mas sim a versão penalizada do scikit-learn. Para aqueles que usam a regressão logística frequentemente, muitas vezes são utilizadas outras ferramentas como a biblioteca statsmodel ou até mesmo fazendo parte da análise em outra linguagem, como R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 números aleatórios entre 0 e 5, uniforme\n",
    "x = np.sort(np.random.rand(30) * 5).reshape(-1, 1)\n",
    "# 30 números aleatórios utilizando a distribuição normal com sigma = 1 e mu = 0\n",
    "ruido = np.random.randn(30, 1)\n",
    "y = ((x + ruido) > 2.5).reshape(-1)\n",
    "\n",
    "regressor = LogisticRegression().fit(x, y)\n",
    "\n",
    "print(regressor.coef_[0], regressor.intercept_)\n",
    "plt.scatter(x, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "graphx = np.linspace(0, 5, 100).reshape(-1, 1)\n",
    "plt.plot(graphx, sigmoide(graphx, k=regressor.coef_[0], x0=-regressor.intercept_), c='k', linewidth=3)\n",
    "plt.plot(graphx, regressor.predict_proba(graphx)[:, 0], c='red', linewidth=3)\n",
    "plt.plot(graphx, regressor.predict_proba(graphx)[:, 1], c='blue', linewidth=3)\n",
    "plt.axhline(0.5, c='gray')\n",
    "plt.axvline(-regressor.intercept_, c='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando a função `predict` podemos encontrar a qual classe o regressor acha que um ponto pertence (ou no caso, \"os pontos\", pois a função é vetorizada)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(regressor.predict(x) == y) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(regressor.predict(x), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando a função `predict_proba`, o regressor retorna a probabilidade de cada classe, segundo o modelo. Se o nosso problema tivesse mais de duas classes, haveriam colunas adicionais.\n",
    "\n",
    "A função `predict` simplesmente retorna qual das classes possui o maior valor em `predict_proba`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.predict_proba(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris\n",
    "\n",
    "Vamos utilizar a base Iris para testar um classificador \"real\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(iris.data, iris.target, test_size=0.5)\n",
    "regressor = LogisticRegression()\n",
    "regressor.fit(xtrain, ytrain)\n",
    "predicao = regressor.predict(xtest)\n",
    "accuracy_score(ytest, predicao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa API da classe `LogisticRegression` é idêntica para todos os classificadores do sklearn:\n",
    "\n",
    "1. Criamos o objeto do modelo utilizando o nome da classe, e passando os hiperparâmetros\n",
    "2. Chamamos a função `fit` nesse objeto, passando os dados de treinamento\n",
    "3. Podemos então utilizar a função `predict` em novos objetos ou no conjunto de testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "modelos = [LogisticRegression(),\n",
    "           DecisionTreeClassifier(),\n",
    "           GaussianNB(),\n",
    "           KNeighborsClassifier(),\n",
    "           MLPClassifier(),\n",
    "           SVC()]\n",
    "\n",
    "for modelo in modelos:\n",
    "    modelo.fit(xtrain, ytrain)\n",
    "    predicao = modelo.predict(xtest)\n",
    "    print(accuracy_score(ytest, predicao))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esses exemplos todos usam os hiperparâmetros padrão, e utilizando dessa forma tratamos todos como caixas-pretas, sem visualização ou explicação do processo. Cada um dos classificadores possui métodos e valores adicionais que podemos usar para melhorar e analisar os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embora não seja recomendado, nós vamos ver a correlação entre as variáveis de entrada (numéricas) e a variável classe. Em geral é um erro calcular a correlação para um dado categórico, mas vamos utilizar por motivos didáticos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aparentemente as variáveis de pétala tem grande poder preditivo sobre a classe, diferente das variáveis de sépala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['petal width (cm)'], df['target']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos temporariamente tratar o problema como binário, tentando prever se uma determinada flor é da classe Setosa (classe 0) ou não."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['setosa'] = df['target'] == 0\n",
    "df['setosa'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['petal width (cm)'], df['setosa']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LogisticRegression(multi_class='multinomial', solver='newton-cg')\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(df['petal width (cm)'].values.reshape(-1, 1),\n",
    "                                                df['setosa'], test_size=0.5)\n",
    "regressor.fit(xtrain, ytrain)\n",
    "print(regressor.coef_, regressor.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(xtrain, ytrain, marker='*')\n",
    "plt.scatter(xtest, ytest, c='r', marker='.')\n",
    "\n",
    "graphx = np.linspace(0, 2.5, 100).reshape(-1, 1)\n",
    "plt.plot(graphx, regressor.predict_proba(graphx)[:, 0], c='r')\n",
    "plt.plot(graphx, regressor.predict_proba(graphx)[:, 1], c='b')\n",
    "plt.axhline(0.5, c='gray')\n",
    "plt.axvline(regressor.intercept_, c='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(ytest, regressor.predict(xtest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problemas multinomiais\n",
    "\n",
    "Existem duas formas principais de trabalhar com dados multinomiais (ou seja, mais de duas classes) em regressão logística. A primeira é a formulação multinomial do problema. O algoritmo padrão para resolver o problema (`solver`) do SK Learn não trata dessa formulação, então é necessário alterar este hiper-parâmetro também."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LogisticRegression(multi_class='multinomial', solver='newton-cg')\n",
    "regressor.fit(df['petal width (cm)'].values.reshape(-1, 1), df['target'])\n",
    "\n",
    "x = np.linspace(0, 2.5, 100).reshape(-1, 1)\n",
    "plt.plot(x, regressor.predict_proba(x)[:, 0], c='r')\n",
    "plt.plot(x, regressor.predict_proba(x)[:, 1], c='b')\n",
    "plt.plot(x, regressor.predict_proba(x)[:, 2], c='g')\n",
    "\n",
    "plt.scatter(df['petal width (cm)'], df['target'] / 2, c='k')\n",
    "\n",
    "regressor.predict_proba(x).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A segunda forma é utilizando o método \"Um contra o resto\" (_One Versus Rest_, OVR). Nesse método, cada classe é considerada um problema binário de \"pertence a classe versus não pertence a classe\", como fizemos com a classe Setosa anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LogisticRegression(multi_class='ovr', solver='newton-cg')\n",
    "regressor.fit(df['petal width (cm)'].values.reshape(-1, 1), df['target'])\n",
    "\n",
    "x = np.linspace(0, 2.5, 100).reshape(-1, 1)\n",
    "plt.plot(x, regressor.predict_proba(x)[:, 0], c='r')\n",
    "plt.plot(x, regressor.predict_proba(x)[:, 1], c='b')\n",
    "plt.plot(x, regressor.predict_proba(x)[:, 2], c='g')\n",
    "\n",
    "plt.scatter(df['petal width (cm)'], df['target'] / 2, c='k')\n",
    "\n",
    "regressor.predict_proba(x).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em ambos os casos, as probabilidades são normalizadas de forma que a linha da matriz `predict_proba` sempre tenha soma 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar documentação da regressão logística:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?LogisticRegression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
